{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b60022-3a22-4245-85cb-49d8690b742b",
   "metadata": {},
   "source": [
    "# Assignement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb0f7d8-fc93-46f9-8faa-b077d8589d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report\n",
    "import skfuzzy as fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d7aee-b27b-405f-bbbc-789f5d401891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset \n",
    "diabetes = datasets.load_diabetes(as_frame = True)\n",
    "X = diabetes.data.values\n",
    "y = diabetes.target.values\n",
    "\n",
    "diabetes.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c508e-0392-4a17-bc20-a7fde55fcc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test spliting\n",
    "test_size=0.2\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493837a9-92ff-4b09-be2c-3c91068ad07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler=StandardScaler()\n",
    "Xtr= scaler.fit_transform(Xtr)\n",
    "Xte= scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b56766-51bb-4a22-a07b-354bd02ca9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters \n",
    "n_clusters = 2\n",
    "m=2\n",
    "\n",
    "# Concatenate target for clustering\n",
    "Xexp= np.concatenate([Xtr, ytr.reshape(-1,1)], axis=1)\n",
    "#Xexp=Xtr\n",
    "\n",
    "# Transpose data for skfuzzy (expects features x samples)\n",
    "Xexp_T = Xexp.T \n",
    "\n",
    "# Fuzzy C-means clustering\n",
    "centers, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    Xexp_T, n_clusters, m=m, error=0.005, maxiter=1000, init=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b282b0a-9745-4a49-875b-4e5b2c89bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sigma (spread) for each cluster\n",
    "sigmas = []\n",
    "for j in range(n_clusters):\n",
    "    # membership weights for cluster j, raised to m\n",
    "    u_j = u[j, :] ** m\n",
    "    # weighted variance for each feature\n",
    "    var_j = np.average((Xexp - centers[j])**2, axis=0, weights=u_j)\n",
    "    sigma_j = np.sqrt(var_j)\n",
    "    sigmas.append(sigma_j)\n",
    "sigmas=np.array(sigmas)# Hard clustering from fuzzy membership\n",
    "\n",
    "# Hard clustering from fuzzy membership\n",
    "cluster_labels = np.argmax(u, axis=0)\n",
    "print(\"Fuzzy partition coefficient (FPC):\", fpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848354f-dc8e-4d69-82ac-4064d4aab185",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = np.argmax(u, axis=0)  \n",
    "\n",
    "# Turn Xexp into a dataframe for plotting\n",
    "df = pd.DataFrame(Xexp, columns=[f\"Feature {i}\" for i in range(Xexp.shape[1])])\n",
    "df[\"Cluster\"] = cluster_labels\n",
    "\n",
    "# Pairplot with hue = cluster\n",
    "sns.pairplot(df, vars=df.columns[:-1], hue=\"Cluster\", palette=\"tab10\", diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880480e2-a9d3-4b03-95e0-ee1e91e8f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Gaussian Membership Function\n",
    "# ---------------------------\n",
    "class GaussianMF(nn.Module):\n",
    "    def __init__(self, centers, sigmas, agg_prob):\n",
    "        super().__init__()\n",
    "        self.centers = nn.Parameter(torch.tensor(centers, dtype=torch.float32))\n",
    "        self.sigmas = nn.Parameter(torch.tensor(sigmas, dtype=torch.float32))\n",
    "        self.agg_prob=agg_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expand for broadcasting\n",
    "        # x: (batch, 1, n_dims), centers: (1, n_rules, n_dims), sigmas: (1, n_rules, n_dims)\n",
    "        diff = abs((x.unsqueeze(1) - self.centers.unsqueeze(0))/self.sigmas.unsqueeze(0)) #(batch, n_rules, n_dims)\n",
    "\n",
    "        # Aggregation\n",
    "        if self.agg_prob:\n",
    "            dist = torch.norm(diff, dim=-1)  # (batch, n_rules) # probablistic intersection\n",
    "        else:\n",
    "            dist = torch.max(diff, dim=-1).values  # (batch, n_rules) # min intersection (min instersection of normal funtion is the same as the max on dist)\n",
    "        \n",
    "        return torch.exp(-0.5 * dist ** 2)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# TSK Model\n",
    "# ---------------------------\n",
    "class TSK(nn.Module):\n",
    "    def __init__(self, n_inputs, n_rules, centers, sigmas,agg_prob=False):\n",
    "        super().__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_rules = n_rules\n",
    "\n",
    "        # Antecedents (Gaussian MFs)\n",
    "        \n",
    "        self.mfs=GaussianMF(centers, sigmas,agg_prob) \n",
    "\n",
    "        # Consequents (linear functions of inputs)\n",
    "        # Each rule has coeffs for each input + bias\n",
    "        self.consequents = nn.Parameter(\n",
    "            torch.randn(n_inputs + 1,n_rules)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, n_inputs)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Compute membership values for each input feature\n",
    "        # firing_strengths: (batch, n_rules)\n",
    "        firing_strengths = self.mfs(x)\n",
    "        \n",
    "        # Normalize memberships\n",
    "        # norm_fs: (batch, n_rules)\n",
    "        norm_fs = firing_strengths / (firing_strengths.sum(dim=1, keepdim=True) + 1e-9)\n",
    "\n",
    "        # Consequent output (linear model per rule)\n",
    "        x_aug = torch.cat([x, torch.ones(batch_size, 1)], dim=1)  # add bias\n",
    "\n",
    "        rule_outputs = torch.einsum(\"br,rk->bk\", x_aug, self.consequents)  # (batch, rules)\n",
    "        # Weighted sum\n",
    "        output = torch.sum(norm_fs * rule_outputs, dim=1, keepdim=True)\n",
    "\n",
    "        return output, norm_fs, rule_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358c67c-76b1-459d-96e6-acff580fd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Gradient Descent Training \n",
    "# ---------------------------\n",
    "def train_gd(model, X, y, epochs=100, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _, _ = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b6092-8df9-470b-a7dd-a2fb65ccba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Hybrid Training (Classic ANFIS)\n",
    "# ---------------------------\n",
    "def train_hybrid_anfis(model, X, y, max_iters=10, gd_epochs=20, lr=1e-3):\n",
    "    train_ls(model, X, y)\n",
    "    for _ in range(max_iters):\n",
    "        # Step A: GD on antecedents (freeze consequents)\n",
    "        model.consequents.requires_grad = False\n",
    "        train_gd(model, X, y, epochs=gd_epochs, lr=lr)\n",
    "\n",
    "        # Step B: LS on consequents (freeze antecedents)\n",
    "        model.consequents.requires_grad = True\n",
    "        model.mfs.requires_grad = False\n",
    "        train_ls(model, X, y)\n",
    "\n",
    "        # Re-enable antecedents\n",
    "        model.mfs.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70e5d9-fadd-4018-861b-4e03cc7efdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Alternative Hybrid Training (LS+ gradient descent on all)\n",
    "# ---------------------------\n",
    "def train_hybrid(model, X, y, epochs=100, lr=1e-4):\n",
    "    # Step 1: LS for consequents\n",
    "    train_ls(model, X, y)\n",
    "    # Step 2: GD fine-tuning\n",
    "    train_gd(model, X, y, epochs=epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6bdc6-25d3-40b7-a547-2de9d2992aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GD_model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])\n",
    "ANFIS_model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])\n",
    "Hybrid_model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebda735-4780-498c-8111-91c8fb671f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with GD\n",
    "train_gd(GD_model, Xtr, ytr.reshape(-1,1), epochs=100, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca041408-4f46-4eb0-b36f-7969e7de79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with ANFIS\n",
    "train_hybrid_anfis(ANFIS_model, Xtr, ytr.reshape(-1,1), max_iters=10, gd_epochs=20, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3247409-694a-49ff-85db-76a745c618b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Hybrid Classic \n",
    "train_hybrid(Hybrid_model, Xtr, ytr.reshape(-1,1), epochs=100, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe738053-c8e5-42cd-bd09-4820eee8d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "y_pred_GD, _, _ = GD_model(Xte)\n",
    "y_pred_ANFIS, _, _ = ANFIS_model(Xte)\n",
    "y_pred_Hybrid, _, _ = Hybrid_model(Xte)\n",
    "\n",
    "# Compute MSE for each\n",
    "mse_GD = mean_squared_error(yte.detach().numpy(), y_pred_GD.detach().numpy())\n",
    "mse_ANFIS = mean_squared_error(yte.detach().numpy(), y_pred_ANFIS.detach().numpy())\n",
    "mse_Hybrid = mean_squared_error(yte.detach().numpy(), y_pred_Hybrid.detach().numpy())\n",
    "\n",
    "print(f\"MSE GD: {mse_GD}\")\n",
    "print(f\"MSE ANFIS: {mse_ANFIS}\")\n",
    "print(f\"MSE Hybrid: {mse_Hybrid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4274a7ae-e378-408d-bc9f-b6f55f8f828a",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822738af-cc27-47b6-9fa3-f5f9e25bcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "diabetes = datasets.fetch_openml(\"diabetes\", version=1, as_frame=True)\n",
    "\n",
    "# Get the full DataFrame (features + target)\n",
    "df = diabetes.frame\n",
    "\n",
    "# Replace string target with binary values directly\n",
    "df[\"class\"] = df[\"class\"].map({\n",
    "    \"tested_negative\": 0,\n",
    "    \"tested_positive\": 1\n",
    "})\n",
    "\n",
    "# Define X and y from the updated DataFrame\n",
    "X = df.drop(columns=\"class\").values\n",
    "y = df[\"class\"].values\n",
    "\n",
    "print(y[:10])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b3b22-7787-4c09-8572-eb394cae7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test spliting\n",
    "test_size=0.2\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecb560-8244-4362-9569-a892d33762ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler=StandardScaler()\n",
    "Xtr= scaler.fit_transform(Xtr)\n",
    "Xte= scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37356e78-0cca-4701-80a0-7fb791f4c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters \n",
    "n_clusters = 2\n",
    "m= 1.5\n",
    "\n",
    "# Concatenate target for clustering\n",
    "Xexp=np.concatenate([Xtr, ytr.reshape(-1, 1)], axis=1)\n",
    "#Xexp=Xtr\n",
    "\n",
    "# Transpose data for skfuzzy (expects features x samples)\n",
    "Xexp_T = Xexp.T \n",
    "\n",
    "# Fuzzy C-means clustering\n",
    "centers, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    Xexp_T, n_clusters, m=m, error=0.005, maxiter=1000, init=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712128cc-48bc-4bb9-9974-6f54e7074bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sigma (spread) for each cluster\n",
    "sigmas = []\n",
    "for j in range(n_clusters):\n",
    "    # membership weights for cluster j, raised to m\n",
    "    u_j = u[j, :] ** m\n",
    "    # weighted variance for each feature\n",
    "    var_j = np.average((Xexp - centers[j])**2, axis=0, weights=u_j)\n",
    "    sigma_j = np.sqrt(var_j)\n",
    "    sigmas.append(sigma_j)\n",
    "sigmas=np.array(sigmas)# Hard clustering from fuzzy membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fb577-76e8-4a05-935f-836014e54fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard clustering from fuzzy membership\n",
    "cluster_labels = np.argmax(u, axis=0)\n",
    "print(\"Fuzzy partition coefficient (FPC):\", fpc)\n",
    "\n",
    "cluster_labels = np.argmax(u, axis=0)  \n",
    "\n",
    "# Turn Xexp into a dataframe for plotting\n",
    "df = pd.DataFrame(Xexp, columns=[f\"Feature {i}\" for i in range(Xexp.shape[1])])\n",
    "df[\"Cluster\"] = cluster_labels\n",
    "\n",
    "# Pairplot with hue = cluster\n",
    "sns.pairplot(df, vars=df.columns[:-1], hue=\"Cluster\", palette=\"tab10\", diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4adce-47fb-4435-84b3-c8c9858dae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "GD_model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])\n",
    "ANFIS_model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])\n",
    "Hybrid_model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b175268-d1cf-40e2-8f4c-44c564e1b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with GD\n",
    "train_gd(GD_model, Xtr, ytr.reshape(-1,1), epochs=100, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c39ef-2e0e-4f5b-bc76-f737fd927f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with ANFIS\n",
    "train_hybrid_anfis(ANFIS_model, Xtr, ytr.reshape(-1,1), max_iters=10, gd_epochs=20, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f77d38-5cb7-4f82-9686-885e12b03d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Hybrid Classic \n",
    "train_hybrid(Hybrid_model, Xtr, ytr.reshape(-1,1), epochs=100, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ce4bcc-9592-416f-8bed-c287784e6b5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GD_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_GD \u001b[38;5;241m=\u001b[39m (\u001b[43mGD_model\u001b[49m(Xte)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\n\u001b[0;32m      3\u001b[0m y_pred_ANFIS \u001b[38;5;241m=\u001b[39m (ANFIS_model(Xte)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\n\u001b[0;32m      4\u001b[0m y_pred_Hybrid \u001b[38;5;241m=\u001b[39m (Hybrid_model(Xte)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GD_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred_GD = (GD_model(Xte)[0] >= 0.5).int()\n",
    "y_pred_ANFIS = (ANFIS_model(Xte)[0] >= 0.5).int()\n",
    "y_pred_Hybrid = (Hybrid_model(Xte)[0] >= 0.5).int\n",
    "\n",
    "# Compute Accuracy for each\n",
    "acc_GD = accuracy_score(yte.detach().numpy(), y_pred_GD.detach().numpy())\n",
    "acc_ANFIS = accuracy_score(yte.detach().numpy(), y_pred_ANFIS.detach().numpy())\n",
    "acc_Hybrid = accuracy_score(yte.detach().numpy(), y_pred_Hybrid.detach().numpy())\n",
    "\n",
    "print(f\"Accuracy GD: {acc_GD:.4f}\")\n",
    "print(f\"Accuracy ANFIS: {acc_ANFIS:.4f}\")\n",
    "print(f\"Accuracy Hybrid: {acc_Hybrid:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
